{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:08:56.163028Z","iopub.execute_input":"2025-01-29T14:08:56.163464Z","iopub.status.idle":"2025-01-29T14:08:56.902378Z","shell.execute_reply.started":"2025-01-29T14:08:56.163411Z","shell.execute_reply":"2025-01-29T14:08:56.901190Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# A simple training pipeline\nThis notebook is a demonstration of how to build a simple neural network from scratch and train it on a real life dataset and use the model to perform predictions","metadata":{}},{"cell_type":"markdown","source":"## Import tools","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:08:56.904575Z","iopub.execute_input":"2025-01-29T14:08:56.905639Z","iopub.status.idle":"2025-01-29T14:09:00.935744Z","shell.execute_reply.started":"2025-01-29T14:08:56.905563Z","shell.execute_reply":"2025-01-29T14:09:00.934470Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Load the dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:09:00.937188Z","iopub.execute_input":"2025-01-29T14:09:00.937740Z","iopub.status.idle":"2025-01-29T14:09:01.292605Z","shell.execute_reply.started":"2025-01-29T14:09:00.937665Z","shell.execute_reply":"2025-01-29T14:09:01.291253Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0    842302         M        17.99         10.38          122.80     1001.0   \n1    842517         M        20.57         17.77          132.90     1326.0   \n2  84300903         M        19.69         21.25          130.00     1203.0   \n3  84348301         M        11.42         20.38           77.58      386.1   \n4  84358402         M        20.29         14.34          135.10     1297.0   \n\n   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0          0.11840           0.27760          0.3001              0.14710   \n1          0.08474           0.07864          0.0869              0.07017   \n2          0.10960           0.15990          0.1974              0.12790   \n3          0.14250           0.28390          0.2414              0.10520   \n4          0.10030           0.13280          0.1980              0.10430   \n\n   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n0  ...          17.33           184.60      2019.0            0.1622   \n1  ...          23.41           158.80      1956.0            0.1238   \n2  ...          25.53           152.50      1709.0            0.1444   \n3  ...          26.50            98.87       567.7            0.2098   \n4  ...          16.67           152.20      1575.0            0.1374   \n\n   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n0             0.6656           0.7119                0.2654          0.4601   \n1             0.1866           0.2416                0.1860          0.2750   \n2             0.4245           0.4504                0.2430          0.3613   \n3             0.8663           0.6869                0.2575          0.6638   \n4             0.2050           0.4000                0.1625          0.2364   \n\n   fractal_dimension_worst  Unnamed: 32  \n0                  0.11890          NaN  \n1                  0.08902          NaN  \n2                  0.08758          NaN  \n3                  0.17300          NaN  \n4                  0.07678          NaN  \n\n[5 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n      <th>Unnamed: 32</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 33 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:09:01.294518Z","iopub.execute_input":"2025-01-29T14:09:01.295639Z","iopub.status.idle":"2025-01-29T14:09:01.303266Z","shell.execute_reply.started":"2025-01-29T14:09:01.295583Z","shell.execute_reply":"2025-01-29T14:09:01.302046Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(569, 33)"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df.drop(columns=[\"id\", \"Unnamed: 32\"], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:09:01.304889Z","iopub.execute_input":"2025-01-29T14:09:01.305335Z","iopub.status.idle":"2025-01-29T14:09:01.319430Z","shell.execute_reply.started":"2025-01-29T14:09:01.305299Z","shell.execute_reply":"2025-01-29T14:09:01.318163Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# After dropping the `id` and `Unnamed: 32` columns\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:09:01.320860Z","iopub.execute_input":"2025-01-29T14:09:01.321209Z","iopub.status.idle":"2025-01-29T14:09:01.362772Z","shell.execute_reply.started":"2025-01-29T14:09:01.321156Z","shell.execute_reply":"2025-01-29T14:09:01.361657Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0         M        17.99         10.38          122.80     1001.0   \n1         M        20.57         17.77          132.90     1326.0   \n2         M        19.69         21.25          130.00     1203.0   \n3         M        11.42         20.38           77.58      386.1   \n4         M        20.29         14.34          135.10     1297.0   \n\n   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0          0.11840           0.27760          0.3001              0.14710   \n1          0.08474           0.07864          0.0869              0.07017   \n2          0.10960           0.15990          0.1974              0.12790   \n3          0.14250           0.28390          0.2414              0.10520   \n4          0.10030           0.13280          0.1980              0.10430   \n\n   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n0         0.2419  ...         25.38          17.33           184.60   \n1         0.1812  ...         24.99          23.41           158.80   \n2         0.2069  ...         23.57          25.53           152.50   \n3         0.2597  ...         14.91          26.50            98.87   \n4         0.1809  ...         22.54          16.67           152.20   \n\n   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n0      2019.0            0.1622             0.6656           0.7119   \n1      1956.0            0.1238             0.1866           0.2416   \n2      1709.0            0.1444             0.4245           0.4504   \n3       567.7            0.2098             0.8663           0.6869   \n4      1575.0            0.1374             0.2050           0.4000   \n\n   concave points_worst  symmetry_worst  fractal_dimension_worst  \n0                0.2654          0.4601                  0.11890  \n1                0.1860          0.2750                  0.08902  \n2                0.2430          0.3613                  0.08758  \n3                0.2575          0.6638                  0.17300  \n4                0.1625          0.2364                  0.07678  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## Train test split","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:09:01.365443Z","iopub.execute_input":"2025-01-29T14:09:01.365822Z","iopub.status.idle":"2025-01-29T14:09:01.376783Z","shell.execute_reply.started":"2025-01-29T14:09:01.365789Z","shell.execute_reply":"2025-01-29T14:09:01.375620Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Scaling the data","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:09:01.378186Z","iopub.execute_input":"2025-01-29T14:09:01.378518Z","iopub.status.idle":"2025-01-29T14:09:01.397034Z","shell.execute_reply.started":"2025-01-29T14:09:01.378487Z","shell.execute_reply":"2025-01-29T14:09:01.395739Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Label Encoding\nSince the output comprises of values `M` and `B`, we need to label encode it since our model would not understand letters","metadata":{}},{"cell_type":"code","source":"encoder = LabelEncoder()\ny_train = encoder.fit_transform(y_train)\ny_test = encoder.transform(y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:09:01.398889Z","iopub.execute_input":"2025-01-29T14:09:01.399279Z","iopub.status.idle":"2025-01-29T14:09:01.405950Z","shell.execute_reply.started":"2025-01-29T14:09:01.399247Z","shell.execute_reply":"2025-01-29T14:09:01.404663Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Numpy arrays to PyTorch tensors","metadata":{}},{"cell_type":"code","source":"X_train_tensor = torch.from_numpy(X_train)\nX_test_tensor = torch.from_numpy(X_test)\ny_train_tensor = torch.from_numpy(y_train)\ny_test_tensor = torch.from_numpy(y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:26:32.991094Z","iopub.execute_input":"2025-01-29T14:26:32.991558Z","iopub.status.idle":"2025-01-29T14:26:32.997946Z","shell.execute_reply.started":"2025-01-29T14:26:32.991519Z","shell.execute_reply":"2025-01-29T14:26:32.996583Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"## Defining the model","metadata":{}},{"cell_type":"markdown","source":"### Important parameters\nDefine the `learning_rate` and the number of `epochs` to train your model with","metadata":{}},{"cell_type":"code","source":"learning_rate = 0.1\nepochs = 25","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:26:33.706865Z","iopub.execute_input":"2025-01-29T14:26:33.707792Z","iopub.status.idle":"2025-01-29T14:26:33.712992Z","shell.execute_reply.started":"2025-01-29T14:26:33.707748Z","shell.execute_reply":"2025-01-29T14:26:33.711664Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"class MySimpleNN():\n    \n    def __init__(self, X):\n        self.X = X\n        self.weights = torch.rand((X.shape[1], 1), dtype=torch.float64, requires_grad=True)\n        self.bias = torch.rand(1, dtype=torch.float64, requires_grad=True)\n\n    def forward(self, X):\n        z = torch.matmul(X, self.weights) + self.bias\n        y_pred = torch.sigmoid(z)\n        return y_pred\n\n    def loss(self, y_pred, y_train):\n        # clamp to prevent log(0)\n        EPSILON = 1e-7\n        y_pred = torch.clamp(y_pred, EPSILON, 1 - EPSILON)\n        loss = - (y_train * torch.log(y_pred) + (1 - y_train) * torch.log(y_pred)).mean()\n        return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:26:33.888850Z","iopub.execute_input":"2025-01-29T14:26:33.889289Z","iopub.status.idle":"2025-01-29T14:26:33.897633Z","shell.execute_reply.started":"2025-01-29T14:26:33.889254Z","shell.execute_reply":"2025-01-29T14:26:33.896262Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"Training pipeline is defined as:\n```\nFor loop from 1 to epochs:\n    Forward pass\n    Calculate loss\n    Backward pass\n    Update parameters\n```","metadata":{}},{"cell_type":"code","source":"model = MySimpleNN(X_train_tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:26:34.252243Z","iopub.execute_input":"2025-01-29T14:26:34.253486Z","iopub.status.idle":"2025-01-29T14:26:34.258494Z","shell.execute_reply.started":"2025-01-29T14:26:34.253446Z","shell.execute_reply":"2025-01-29T14:26:34.257424Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"for i in range(1, epochs + 1):\n\n    # forward pass\n    y_pred = model.forward(X_train_tensor)\n\n    # calculate loss\n    loss = model.loss(y_pred, y_train_tensor)\n\n    # backward pass\n    loss.backward()\n\n    # update parameters\n    with torch.no_grad():\n        model.weights -= learning_rate * model.weights.grad\n        model.bias -= learning_rate * model.bias.grad\n\n    # zero gradients\n    model.weights.grad.zero_()\n    model.bias.grad.zero_()\n\n    print(f\"Epoch {i} / {epochs}: Loss: {loss.item()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:26:34.446603Z","iopub.execute_input":"2025-01-29T14:26:34.447069Z","iopub.status.idle":"2025-01-29T14:26:34.509552Z","shell.execute_reply.started":"2025-01-29T14:26:34.447030Z","shell.execute_reply":"2025-01-29T14:26:34.508220Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 / 25: Loss: 3.025738525584375\nEpoch 2 / 25: Loss: 2.7856547006638657\nEpoch 3 / 25: Loss: 2.5489134023313205\nEpoch 4 / 25: Loss: 2.3162605249766295\nEpoch 5 / 25: Loss: 2.088636913312271\nEpoch 6 / 25: Loss: 1.8672274232724744\nEpoch 7 / 25: Loss: 1.6535146203218625\nEpoch 8 / 25: Loss: 1.4493231192053968\nEpoch 9 / 25: Loss: 1.2568242026078285\nEpoch 10 / 25: Loss: 1.0784528216588718\nEpoch 11 / 25: Loss: 0.9166848998357351\nEpoch 12 / 25: Loss: 0.77365573517568\nEpoch 13 / 25: Loss: 0.6506903322742491\nEpoch 14 / 25: Loss: 0.5479341088358067\nEpoch 15 / 25: Loss: 0.46428886136088837\nEpoch 16 / 25: Loss: 0.39768405355499553\nEpoch 17 / 25: Loss: 0.3455208029782115\nEpoch 18 / 25: Loss: 0.30510207683663876\nEpoch 19 / 25: Loss: 0.2739415274238381\nEpoch 20 / 25: Loss: 0.24992327193456282\nEpoch 21 / 25: Loss: 0.23133942666649085\nEpoch 22 / 25: Loss: 0.21685488732416552\nEpoch 23 / 25: Loss: 0.2054441526868665\nEpoch 24 / 25: Loss: 0.19632759319846943\nEpoch 25 / 25: Loss: 0.1889177251276414\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    y_pred_test = model.forward(X_test_tensor)\n    y_pred_test = (y_pred_test > 0.9).float()\n    accuracy = (y_pred_test == y_test_tensor).float().mean()\n    print(f\"Accuracy: {accuracy.item()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:26:36.976112Z","iopub.execute_input":"2025-01-29T14:26:36.976592Z","iopub.status.idle":"2025-01-29T14:26:36.986056Z","shell.execute_reply.started":"2025-01-29T14:26:36.976552Z","shell.execute_reply":"2025-01-29T14:26:36.984286Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.5603262782096863\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"## Defining an nn.Module model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:26:37.711171Z","iopub.execute_input":"2025-01-29T14:26:37.711602Z","iopub.status.idle":"2025-01-29T14:26:37.717986Z","shell.execute_reply.started":"2025-01-29T14:26:37.711566Z","shell.execute_reply":"2025-01-29T14:26:37.715936Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"class NNModel(nn.Module):\n    def __init__(self, num_features):\n        super().__init__()\n        self.linear = nn.Linear(num_features, 1)\n        self.sigmoid = nn.Sigmoid()\n    def forward(self, features):\n        out = self.linear(features)\n        out = self.sigmoid(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:28:17.201765Z","iopub.execute_input":"2025-01-29T14:28:17.202220Z","iopub.status.idle":"2025-01-29T14:28:17.210641Z","shell.execute_reply.started":"2025-01-29T14:28:17.202185Z","shell.execute_reply":"2025-01-29T14:28:17.209083Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"learning_rate = 0.1\nepochs = 25","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:28:17.572783Z","iopub.execute_input":"2025-01-29T14:28:17.573313Z","iopub.status.idle":"2025-01-29T14:28:17.579485Z","shell.execute_reply.started":"2025-01-29T14:28:17.573262Z","shell.execute_reply":"2025-01-29T14:28:17.577920Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"loss_function = nn.BCELoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:36:26.422938Z","iopub.execute_input":"2025-01-29T14:36:26.423368Z","iopub.status.idle":"2025-01-29T14:36:26.429541Z","shell.execute_reply.started":"2025-01-29T14:36:26.423334Z","shell.execute_reply":"2025-01-29T14:36:26.428146Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"model = NNModel(X_train_tensor.shape[1])\noptimizer = torch.optim.SGD(model.parameters, lr=learning_rate)\nfor epoch in range(epochs):\n    y_pred = model(X_train_tensor)\n    loss = loss_function(y_pred, y_train_tensor.view(-1, 1))\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    print(f\"Epoch: {epoch + 1}, Loss: {loss.item()}\")\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:39:56.751990Z","iopub.execute_input":"2025-01-29T14:39:56.752464Z","iopub.status.idle":"2025-01-29T14:39:56.820341Z","shell.execute_reply.started":"2025-01-29T14:39:56.752409Z","shell.execute_reply":"2025-01-29T14:39:56.818303Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[58], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m NNModel(X_train_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      4\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(X_train_tensor)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/sgd.py:56\u001b[0m, in \u001b[0;36mSGD.__init__\u001b[0;34m(self, params, lr, momentum, dampening, weight_decay, nesterov, maximize, foreach, differentiable, fused)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nesterov \u001b[38;5;129;01mand\u001b[39;00m (momentum \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dampening \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNesterov momentum requires a momentum and zero dampening\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_supports_amp_scaling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:360\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate: DefaultDict[torch\u001b[38;5;241m.\u001b[39mTensor, Any] \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 360\u001b[0m param_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(param_groups) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer got an empty parameter list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: 'method' object is not iterable"],"ename":"TypeError","evalue":"'method' object is not iterable","output_type":"error"}],"execution_count":58},{"cell_type":"code","source":"with torch.no_grad():\n    y_pred_test = model.forward(X_test_tensor)\n    y_pred_test = (y_pred_test > 0.9).float()\n    accuracy = (y_pred_test == y_test_tensor).float().mean()\n    print(f\"Accuracy: {accuracy.item()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T14:28:41.226529Z","iopub.execute_input":"2025-01-29T14:28:41.227029Z","iopub.status.idle":"2025-01-29T14:28:41.235893Z","shell.execute_reply.started":"2025-01-29T14:28:41.226991Z","shell.execute_reply":"2025-01-29T14:28:41.234554Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.6228070259094238\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}